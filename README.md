# ğŸ” Resilient Forecaster
### Defending LSTM Models Against Data Poisoning Attacks

---

## ğŸ“Œ Overview
**Resilient Forecaster** demonstrates how machine learning models can be vulnerable to **data poisoning attacks** and how defensive mechanisms can restore model performance. 

We simulate an attack on an LSTM-based stock price prediction system and measure:
* ğŸ“‰ **Performance degradation** due to poisoning.
* ğŸ›¡ **Recovery** after applying statistical defense.

---

## ğŸ¯ Problem Statement
Machine learning models rely heavily on clean training data. If an attacker manipulates training labels, the model learns incorrect patterns.

> **Can we detect and recover from data poisoning using automated defense?**

---

## ğŸ§  Project Architecture
The workflow follows a modular pipeline:
1. **Raw Stock Data:** Ingested via `yFinance`.
2. **Preprocessing:** Scaling and sequence creation (Time-Series Windows).
3. **Execution:** Clean Training â†’ Poisoned Training â†’ Defended Training.
4. **Comparison:** Evaluation via Mean Squared Error (MSE).

---

## âš™ï¸ Technologies Used
* **Python** (Core Language)
* **TensorFlow / Keras** (Deep Learning)
* **NumPy & Pandas** (Data Manipulation)
* **Scikit-learn** (Preprocessing)
* **Matplotlib** (Visualization)
* **yFinance** (Stock Data)

---

## ğŸ—‚ Project Structure
```text
Resilient_Forecaster/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ attacker.py        # Poisoning logic
â”‚   â”œâ”€â”€ defender.py        # Restoration logic
â”‚   â”œâ”€â”€ model_lstm.py      # LSTM architecture
â”‚   â””â”€â”€ data_loader.py     # Data fetching
â”œâ”€â”€ main.py                # Main pipeline
â””â”€â”€ README.md              # Documentation
